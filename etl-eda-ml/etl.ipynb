{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos - movies_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Función para desanidar listas y diccionarios dentro de una columna\n",
    "def desanidar_columna(df, columna, key=None):\n",
    "    def desanidar_elemento(elemento, key):\n",
    "        if isinstance(elemento, str):\n",
    "            try:\n",
    "                elemento = ast.literal_eval(elemento)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return None\n",
    "        if isinstance(elemento, list):\n",
    "            if key:\n",
    "                return ', '.join([str(d.get(key, '')) for d in elemento if isinstance(d, dict)])\n",
    "            return ', '.join([str(d) for d in elemento])\n",
    "        if isinstance(elemento, dict):\n",
    "            if key:\n",
    "                return elemento.get(key, None)\n",
    "            return str(elemento)\n",
    "        return None\n",
    "\n",
    "    return df[columna].apply(lambda x: desanidar_elemento(x, key))\n",
    "\n",
    "# Se carga el dataset de peliculas\n",
    "movies_df = pd.read_csv('../../movies_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrección para 'belongs_to_collection': Extraer 'id' del diccionario, manejando casos vacíos y asegurando que sean enteros\n",
    "movies_df['belongs_to_collection'] = movies_df['belongs_to_collection'].apply(\n",
    "    lambda x: int(ast.literal_eval(x)['id']) if isinstance(x, str) and ast.literal_eval(x) and isinstance(ast.literal_eval(x), dict) else None\n",
    ")\n",
    "movies_df['genres'] = desanidar_columna(movies_df, 'genres', 'name')\n",
    "movies_df['production_companies'] = desanidar_columna(movies_df, 'production_companies', 'name')\n",
    "movies_df['production_countries'] = desanidar_columna(movies_df, 'production_countries', 'iso_3166_1')\n",
    "movies_df['spoken_languages'] = desanidar_columna(movies_df, 'spoken_languages', 'iso_639_1')\n",
    "\n",
    "# Convertimos la columna 'id' en movies_df a numérica y asegurar que sea entera para luego facilitar el mergeo de datasets\n",
    "movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos - credits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de los créditos\n",
    "credits_df = pd.read_csv('../../credits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las columnas en credits_df\n",
    "credits_df['cast'] = desanidar_columna(credits_df, 'cast', 'name')\n",
    "\n",
    "# Separamos actores y directores\n",
    "credits_df['actors'] = credits_df['cast'].apply(lambda x: ', '.join([actor for actor in x.split(', ')[:5]]))\n",
    "\n",
    "# Corrección para 'directors': Buscar \"Director\" en lugar de \"Directing\"\n",
    "def extract_directors(crew_str):\n",
    "    try:\n",
    "        crew_list = ast.literal_eval(crew_str)\n",
    "        directors = [member['name'] for member in crew_list if member.get('job') == 'Director']\n",
    "        return ', '.join(directors)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "credits_df['directors'] = credits_df['crew'].apply(extract_directors)\n",
    "\n",
    "# Mantenemos solo las columnas relevantes en credits_df\n",
    "credits_df = credits_df[['id', 'actors', 'directors']]\n",
    "\n",
    "# Convertimos la columna 'id' en credits_df a numérica y asegurar que sea entera para luego facilitar el mergeo de datasets\n",
    "credits_df['id'] = pd.to_numeric(credits_df['id'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mergeamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los datasets\n",
    "merged_df = pd.merge(movies_df, credits_df, on='id', how='left')\n",
    "\n",
    "# Hacemos unas transformaciones adicionales en merged_df\n",
    "merged_df['revenue'] = pd.to_numeric(merged_df['revenue'], errors='coerce').fillna(0)\n",
    "merged_df['budget'] = pd.to_numeric(merged_df['budget'], errors='coerce').fillna(0)\n",
    "merged_df = merged_df.dropna(subset=['release_date'])\n",
    "merged_df['release_date'] = pd.to_datetime(merged_df['release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "merged_df['release_year'] = merged_df['release_date'].dt.year.astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos el retorno de inversion (revenue / budget), luego eliminamos las columnas que no utilizaremos segun la consigna del proyecto, y finalizaremos guardando un nuevo csv con todos los datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el retorno de inversión\n",
    "merged_df['return'] = merged_df.apply(lambda row: row['revenue'] / row['budget'] if row['budget'] > 0 else 0, axis=1)\n",
    "\n",
    "# Eliminamos las columnas no utilizadas segun los requisitos del trabajo\n",
    "columns_to_drop = ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convertimos 'belongs_to_collection' a entero, para manejar valores nulos\n",
    "merged_df['belongs_to_collection'] = merged_df['belongs_to_collection'].astype('Int64')\n",
    "\n",
    "# Validamos y eliminamos filas que no cumplen con los tipos de datos especificados\n",
    "def validate_and_remove_invalid_rows(df, target_dtypes):\n",
    "    for column, dtype in target_dtypes.items():\n",
    "        try:\n",
    "            df[column] = df[column].astype(dtype)\n",
    "        except ValueError:\n",
    "            # Mantener filas con datos válidos y eliminar las que no cumplen con el tipo de dato\n",
    "            if dtype in ['Int64', 'float64']:\n",
    "                df = df[pd.to_numeric(df[column], errors='coerce').notnull()]\n",
    "            else:\n",
    "                df = df[df[column].apply(lambda x: isinstance(x, dtype))]\n",
    "    return df\n",
    "\n",
    "# Aplicamos tipos de datos y mantenemos datos desanidados\n",
    "target_dtypes = {\n",
    "    'belongs_to_collection': 'Int64',\n",
    "    'budget': 'float64',\n",
    "    'genres': 'object',\n",
    "    'id': 'Int64',\n",
    "    'original_language': 'object',\n",
    "    'overview': 'object',\n",
    "    'popularity': 'float64',\n",
    "    'production_companies': 'object',\n",
    "    'production_countries': 'object',\n",
    "    'release_date': 'datetime64[ns]',\n",
    "    'revenue': 'float64',\n",
    "    'runtime': 'float64',\n",
    "    'spoken_languages': 'object',\n",
    "    'status': 'object',\n",
    "    'tagline': 'object',\n",
    "    'title': 'object',\n",
    "    'vote_average': 'float64',\n",
    "    'vote_count': 'float64',\n",
    "    'actors': 'object',\n",
    "    'directors': 'object',\n",
    "    'release_year': 'Int64',\n",
    "    'return': 'float64'\n",
    "}\n",
    "\n",
    "merged_df = validate_and_remove_invalid_rows(merged_df, target_dtypes)\n",
    "\n",
    "# Guardarmos entonces el dataset limpio\n",
    "merged_df.to_csv('../../dataset_limpio.csv', index=False)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este ETL fue realizado en Colab de Google"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
